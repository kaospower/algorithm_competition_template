Pattern Recognition and Machine Learning  
# Preface  
Bayesian methods  
# Mathematical notation
# 1.Introduction
概率论  
决策理论  
信息论  
# 2.Probability Distributions  
# 2.3 The Gaussian Distribution  
# Mixtures of Gaussians  
mixture of Gaussians:  
$p(x)=\displaystyle\sum_{k=1}^K \pi_k\mathcal N(x|\mu_k,\Sigma_k)$  
$\pi_k$:mixing coefficients  
$\displaystyle\sum_{k=1}^K \pi_k=1$  

# 3.Linear Models for Regression
# 4.Linear Models for Classification
# 5.Neural Networks
# 6.Kernel Methods
# 7.Sparse Kernel Machines
# 8.Graphical Models
# 9.Mixture Models and EM
A general technique for finding maximum likelihood estimators
in latent variable models is the expectation-maximization(EM) algorithm.  
Gaussian mixture distribution.  
Gaussian mixture models are widely used in data mining, pattern recognition,
machine learning, and statistical analysis.  
In many applications, their parameters are determined by maximum likelihood,
typically using the EM algorithm.  

# 10.Approximate Inference
# 11.Sampling Methods
# 12.Continuous Latent Variables
# 13.Sequential Data
# 14.Combining Models
